{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tpgjs97/company-project/blob/master/%EC%A0%84%EC%B2%98%EB%A6%AC/smartnurse_%EC%A0%84%EC%B2%98%EB%A6%AC%EC%BD%94%EB%93%9C_%EC%84%B8%ED%97%8C_(2023_11_21).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYWCUreaE8Lz"
      },
      "outputs": [],
      "source": [
        "!pip install nltk pandas konlpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZl9wp6s0eZl"
      },
      "outputs": [],
      "source": [
        "!apt-get install -y fonts-nanum\n",
        "!fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 라이브러리 불러오기"
      ],
      "metadata": {
        "id": "oedssRYvckZ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "D7YyLsRQg5lZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00KkESbeIrkm"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# NLTK 리소스 다운로드\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터 불러오기"
      ],
      "metadata": {
        "id": "6wd2oHeacnY9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 617,
      "metadata": {
        "id": "mgd98dEwI6-P"
      },
      "outputs": [],
      "source": [
        "# ncp JSON 파일 열기\n",
        "ncp_filename = '/content/drive/MyDrive/ColabNotebooks/YearDreamSchool/FinalProject/Data/nursingrecord_ncp.json'\n",
        "with open(ncp_filename, 'r') as file:\n",
        "    ncp_data = json.load(file)\n",
        "\n",
        "# aws JSON 파일 열기\n",
        "aws_filename = '/content/drive/MyDrive/ColabNotebooks/YearDreamSchool/FinalProject/Data/nursingrecord_aws.json'\n",
        "with open(aws_filename, 'r') as file:\n",
        "    aws_data = json.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# JSON 문자열을 파이썬 딕셔너리로 변환하는 함수\n",
        "def parse_json(json_str):\n",
        "    try:\n",
        "        return json.loads(json_str)\n",
        "    except json.JSONDecodeError:\n",
        "        return {}  # JSON 파싱 에러 시 빈 딕셔너리 반환\n",
        "\n",
        "# 각 레코드에 대해 'content' 필드를 파싱\n",
        "for item in ncp_data:\n",
        "    item['content'] = parse_json(item['content'])\n",
        "\n",
        "for item in aws_data:\n",
        "    item['content'] = parse_json(item['content'])\n",
        "\n",
        "\n",
        "# 데이터프레임 생성\n",
        "ncp_df = pd.DataFrame(ncp_data)\n",
        "aws_df = pd.DataFrame(aws_data)"
      ],
      "metadata": {
        "id": "cdf5kUD9_zMF"
      },
      "execution_count": 618,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([ncp_df, aws_df])\n",
        "df['content'] = df['content'].astype(str)\n",
        "df = df.drop_duplicates()\n",
        "df"
      ],
      "metadata": {
        "id": "fvXI9MUwfL8K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 전처리"
      ],
      "metadata": {
        "id": "GNaqAtfWcu5r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 620,
      "metadata": {
        "id": "GdDKS1kPLQs7"
      },
      "outputs": [],
      "source": [
        "NANDA_columns = ['domain', 'class', 'diagnosis', 'collectingData', 'goal', 'plan', 'interventions', 'evaluation']\n",
        "SOAPIE_columns = ['subjective', 'objective', 'assessment', 'planning', 'interventions', 'evaluation']\n",
        "FOCUS_DAR_columns = ['focus', 'data', 'action', 'response']\n",
        "NARRATIVE_NOTES_columns = ['narrativeNote']\n",
        "NURSING_columns = ['assessment', 'diagnosisRelate', 'diagnosis', 'goal', 'plan', 'interventions', 'evaluation']\n",
        "\n",
        "def pre_processing(ncp_df, aws_df, record_type, columns)  :\n",
        "    # 특정 'record_type' 행들만 필터링\n",
        "    record_type_dict = {'NANDA' : 0, 'SOAPIE' : 1, 'FOCUS_DAR' : 2, 'NARRATIVE_NOTES' : 3, 'NURSING' : 4}\n",
        "    ncp_record_type = ncp_df[ncp_df['record_type'] == record_type_dict[record_type]]\n",
        "    aws_record_type = aws_df[aws_df['record_type'] == record_type_dict[record_type]]\n",
        "\n",
        "    # 'content' 열을 확장하여 새로운 데이터 프레임 생성\n",
        "    ncp_content_df = pd.json_normalize(ncp_record_type['content'])\n",
        "    aws_content_df = pd.json_normalize(aws_record_type['content'])\n",
        "\n",
        "    # 필요한 열만 가져오기\n",
        "    ncp_content_df = ncp_content_df[columns]\n",
        "    aws_content_df = aws_content_df[columns]\n",
        "\n",
        "    # 두 데이터프레임 합치기\n",
        "    df = pd.concat([ncp_content_df, aws_content_df])\n",
        "\n",
        "    # 중복된 행 제거\n",
        "    df = df.drop_duplicates()\n",
        "    return df\n",
        "\n",
        "# 전처리 한 데이터프레임 불러오기\n",
        "nanda_df = pre_processing(ncp_df, aws_df, 'NANDA', NANDA_columns)\n",
        "soapie_df = pre_processing(ncp_df, aws_df, 'SOAPIE', SOAPIE_columns)\n",
        "focus_dar_df = pre_processing(ncp_df, aws_df, 'FOCUS_DAR', FOCUS_DAR_columns)\n",
        "narrative_notes_df = pre_processing(ncp_df, aws_df, 'NARRATIVE_NOTES', NARRATIVE_NOTES_columns)\n",
        "nursing_df = pre_processing(ncp_df, aws_df, 'NURSING', NURSING_columns)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 필터링 조건에 맞지 않는 행을 확인하는 함수\n",
        "def is_valid_row(text):\n",
        "    # 숫자만 있는 경우\n",
        "    if re.fullmatch(r'\\d+', text):\n",
        "        return False\n",
        "    # 영어 알파벳만 있는 경우\n",
        "    if re.fullmatch(r'[a-zA-Z]+', text):\n",
        "        return False\n",
        "    # 한글 자음 또는 모음만 있는 경우\n",
        "    if re.fullmatch(r'[ㄱ-ㅎㅏ-ㅣ]+', text):\n",
        "        return False\n",
        "    # 특수 문자만 있는 경우\n",
        "    if re.fullmatch(r'[^\\w\\s]+', text):\n",
        "        return False\n",
        "\n",
        "    return True\n",
        "\n",
        "# 필터링 조건에 맞지 않는 단어를 제거하는 함수\n",
        "def remove_invalid_words(text):\n",
        "    if is_valid_row(str(text)) :\n",
        "        valid_words = text\n",
        "    else :\n",
        "        valid_words = pd.NA # 빈 문자열 대신 pd.NA 반환\n",
        "\n",
        "    return valid_words\n",
        "\n",
        "# 조건에 맞는 단어로 대체하는 함수\n",
        "def text_preprocessing(text):\n",
        "    if text is not pd.NA :\n",
        "        text = text.replace('\\\\n', ' ')\n",
        "        text = text.replace('\\n', ' ')\n",
        "        txt = re.sub('[^가-힣a-zA-Z0-9./%]', ' ', text) # 한글과 영어 소문자만 남기고 다른 글자 모두 제거\n",
        "    else :\n",
        "        txt = pd.NA\n",
        "\n",
        "    return txt\n",
        "\n",
        "# 글자 수가 특정 개수를 넘어가지 못한 행을 제거하는 함수\n",
        "def filter_rows_by_length(df, min_length=2):\n",
        "    condition = df.apply(lambda col: col.apply(lambda x: len(str(x))) >= min_length).all(axis=1)\n",
        "    df_filtered = df[condition]\n",
        "\n",
        "    return df_filtered"
      ],
      "metadata": {
        "id": "Hv--ZTz6PcVF"
      },
      "execution_count": 621,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def function_apply(df) :\n",
        "    # 조건을 만족하는 단어만 남김\n",
        "    for column in df.columns :\n",
        "        df[column] = df[column].apply(remove_invalid_words)\n",
        "        df[column] = df[column].apply(text_preprocessing)\n",
        "\n",
        "    # Null값이 있는 행을 모두 제거\n",
        "    df = df.dropna()\n",
        "\n",
        "    # 글자 수를 필터로한 함수 적용 (글자수가 3 미만인 행)\n",
        "    df = filter_rows_by_length(df, 3)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "H8f9xVCICQ1d"
      },
      "execution_count": 622,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nanda_df = function_apply(nanda_df)\n",
        "soapie_df = function_apply(soapie_df)\n",
        "focus_dar_df = function_apply(focus_dar_df)\n",
        "narrative_notes_df = function_apply(narrative_notes_df)\n",
        "nursing_df = function_apply(nursing_df)"
      ],
      "metadata": {
        "id": "Wiu0DdUHCphs"
      },
      "execution_count": 623,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pd.set_option('display.max_rows',10)\n",
        "print(len(nanda_df), len(soapie_df), len(focus_dar_df), len(narrative_notes_df), len(nursing_df))\n",
        "print(len(nanda_df) + len(soapie_df) + len(focus_dar_df) + len(narrative_notes_df) + len(nursing_df))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ttwz9vuyYRet",
        "outputId": "09615497-f2b7-46dd-f234-fd45770517c1"
      },
      "execution_count": 624,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1342 713 1659 13336 299\n",
            "17349\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discussion\n",
        "\n",
        "### 1. Nanda의 collectingData에는 주관적 정보(S) 객관적 정보(O)가 구분되어있는 경우가 약 8% 정도 존재.\n"
      ],
      "metadata": {
        "id": "QbjFW-5Kz8rN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"주관적, 객관적 정보로 나누어져 기술된 정보의 개수 : {len(nanda_df[(nanda_df['collectingData'].str.startswith('S ')) | (nanda_df['collectingData'].str.startswith('주관적 '))])} \\n전체 개수 : {len(nanda_df)}\", '\\n')\n",
        "\n",
        "for i in nanda_df[(nanda_df['collectingData'].str.startswith('S ')) | (nanda_df['collectingData'].str.startswith('주관적 '))]['collectingData'].index :\n",
        "    print(nanda_df[(nanda_df['collectingData'].str.startswith('S ')) | (nanda_df['collectingData'].str.startswith('주관적 '))]['collectingData'][i])"
      ],
      "metadata": {
        "id": "KNtzYv8fsc-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QecCl1Ju0Gt2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}